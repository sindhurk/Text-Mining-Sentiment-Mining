{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this workshop we perform document clustering using sklearn\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>trade</td>\n",
       "      <td>brazil anti inflation plan limps to anniversar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>crude</td>\n",
       "      <td>diamond shamrock dia cuts crude prices diamond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>crude</td>\n",
       "      <td>opec may have to meet to firm prices analysts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>crude</td>\n",
       "      <td>texaco canada cuts crude prices canadian cts b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>crude</td>\n",
       "      <td>texaco canada txc lowers crude postings texaco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class                                               Text\n",
       "15  trade  brazil anti inflation plan limps to anniversar...\n",
       "43  crude  diamond shamrock dia cuts crude prices diamond...\n",
       "55  crude  opec may have to meet to firm prices analysts ...\n",
       "76  crude  texaco canada cuts crude prices canadian cts b...\n",
       "77  crude  texaco canada txc lowers crude postings texaco..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The \"Class\" labels here are only used for sanity check of the clusters found later.\n",
    "# Remember, in actual use of document clustering, the documents DON'T come with labeled classes.\n",
    "# It's unsupervised learning.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\hp\\Desktop\\TM\\Week4\")\n",
    "news=pd.read_table('r8-train-all-terms.txt',header=None,names = [\"Class\", \"Text\"])\n",
    "subnews=news[(news.Class==\"trade\")| (news.Class=='crude')|(news.Class=='money-fx') ]\n",
    "subnews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The output of each document is a list of tokens.\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "mystopwords=stopwords.words(\"English\") + ['one', 'become', 'get', 'make', 'take']\n",
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "\n",
    "def pre_process(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens=[ WNlemma.lemmatize(t.lower()) for t in tokens]\n",
    "    tokens=[ t for t in tokens if t not in mystopwords]\n",
    "    tokens = [ t for t in tokens if len(t) >= 3 ]\n",
    "    text_after_process=\" \".join(tokens)\n",
    "    return(text_after_process)\n",
    "\n",
    "# Apply preprocessing to every document in the training set.\n",
    "text = subnews['Text']\n",
    "toks = text.apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(710, 2500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tfidf matrix\n",
    "vectorizer = TfidfVectorizer(max_df=0.7, max_features=2500,\n",
    "                             min_df=3, stop_words=mystopwords,\n",
    "                             use_idf=True)\n",
    "X = vectorizer.fit_transform(toks)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use SVD to reduce dimensions\n",
    "svd = TruncatedSVD(300)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "X_lsa = lsa.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance of the SVD step: 85%\n"
     ]
    }
   ],
   "source": [
    "# Check how much variance is explained\n",
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now the actual clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km3 = KMeans(n_clusters=3, init='k-means++', max_iter=100, n_init=1)\n",
    "%time km3.fit(X_lsa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How do we know the clustering result is good or not?\n",
    "# If we have labels available, we can use this to derive how coherent the clusters are.\n",
    "# Homogeneity: each cluster contains only members of a single class\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "labels = subnews['Class']\n",
    "print(\"Homogeneity for 3 clusters: %0.3f\" % metrics.homogeneity_score(labels, km3.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's try some other K values to compare their metrics\n",
    "km2 = KMeans(n_clusters=2, init='k-means++', max_iter=100, n_init=1)\n",
    "%time km2.fit(X_lsa)\n",
    "\n",
    "km4 = KMeans(n_clusters=4, init='k-means++', max_iter=100, n_init=1)\n",
    "%time km4.fit(X_lsa)\n",
    "\n",
    "km5 = KMeans(n_clusters=5, init='k-means++', max_iter=100, n_init=1)\n",
    "%time km5.fit(X_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What are their homogeneity scores?\n",
    "print(\"Homogeneity for 2 clusters: %0.3f\" % metrics.homogeneity_score(labels, km2.labels_))\n",
    "print(\"Homogeneity for 4 clusters: %0.3f\" % metrics.homogeneity_score(labels, km4.labels_))\n",
    "print(\"Homogeneity for 5 clusters: %0.3f\" % metrics.homogeneity_score(labels, km5.labels_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Completeness: all members of a given class are assigned to the same cluster\n",
    "\n",
    "print(\"Completeness for 2 clusters: %0.3f\" % metrics.completeness_score(labels, km2.labels_))\n",
    "print(\"Completeness for 3 clusters: %0.3f\" % metrics.completeness_score(labels, km3.labels_))\n",
    "print(\"Completeness for 4 clusters: %0.3f\" % metrics.completeness_score(labels, km4.labels_))\n",
    "print(\"Completeness for 5 clusters: %0.3f\" % metrics.completeness_score(labels, km5.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Silhouette: more similar within clusters, more distant between clusters\n",
    "# The higher the better\n",
    "print(\"Silhouette Coefficient for 2 clusters: %0.3f\"\n",
    "      % metrics.silhouette_score(X_lsa, km2.labels_))\n",
    "print(\"Silhouette Coefficient for 3 clusters: %0.3f\"\n",
    "      % metrics.silhouette_score(X_lsa, km3.labels_))\n",
    "print(\"Silhouette Coefficient for 4 clusters: %0.3f\"\n",
    "      % metrics.silhouette_score(X_lsa, km4.labels_))\n",
    "print(\"Silhouette Coefficient for 5 clusters: %0.3f\"\n",
    "      % metrics.silhouette_score(X_lsa, km5.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We still need to see the more representative words for each cluster to understand them.\n",
    "\n",
    "def print_terms(cm, num):\n",
    "    original_space_centroids = svd.inverse_transform(cm.cluster_centers_)\n",
    "    order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(num):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the terms for the 2-cluster model\n",
    "print_terms(km2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_terms(km3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_terms(km4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_terms(km5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's map the cluster label to the categories to see where is the confusion\n",
    "\n",
    "dict = {2: 'crude', 1: 'money-fx', 0: 'trade'}\n",
    "cluster_labels = [ dict[c] for c in km3.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(metrics.confusion_matrix(cluster_labels, labels))\n",
    "print(np.mean(cluster_labels == labels) )\n",
    "print(metrics.classification_report(cluster_labels, labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
